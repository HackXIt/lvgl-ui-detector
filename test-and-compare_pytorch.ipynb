{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "\n",
    "This notebook is non-functional and is a work in progress for later model comparison against other models using pytorch.\n",
    "\n",
    "It was previously used for early testing of the data generation using the YOLOv3 baseline project.\n",
    "At that time, the dataset looked different and was accustomed to the YOLOv3 baseline project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "!echo \"Hello World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notebook is intended to be run inside a tensorflow docker container\n",
    "# To run without container, run: %pip install torch torchvision\n",
    "# Additional packages\n",
    "%pip install numpy torch>=1.0 torchvision matplotlib tensorflow tensorboard tensorboardX terminaltables pillow tqdm\n",
    "# %pip install matplotlib\n",
    "# %pip install numpy\n",
    "# %pip install pillow\n",
    "# %pip install opencv-python-headless\n",
    "# %pip install torchvision\n",
    "# # %pip install torch>=1.0\n",
    "# # %pip install tensorflow\n",
    "# # %pip install tensorboard\n",
    "# %pip install terminaltables\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "replace = (\"/app/project/tmp\", \"/app/project\")\n",
    "def replace_path(replace: tuple, file: str):\n",
    "    with open(file, 'r+') as f:\n",
    "        lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            # Replace occurence of replace[0] with replace[1]\n",
    "            line = line.replace(replace[0], replace[1])\n",
    "            print(line)\n",
    "            lines[i] = line\n",
    "        f.seek(0)\n",
    "        f.writelines(lines)\n",
    "        f.truncate()\n",
    "custom_file = os.path.join(os.getcwd(), 'data', 'custom.data')\n",
    "test_file = os.path.join(os.getcwd(), 'data', 'test.txt')\n",
    "train_file = os.path.join(os.getcwd(), 'data', 'train.txt')\n",
    "val_file = os.path.join(os.getcwd(), 'data', 'val.txt')\n",
    "files = [custom_file, test_file, train_file, val_file]\n",
    "for file in files:\n",
    "    replace_path(replace, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "RGB_MAX = 255.0\n",
    "BASE_DIR = '/app/project/' # Mounted project directory inside container\n",
    "IMG_SIZE = 416 # Always square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Paths for data\n",
    "baseline_dir = os.path.join(BASE_DIR, 'baseline', 'PyTorch-YOLOv3')\n",
    "config_dir = os.path.join(baseline_dir, 'config')\n",
    "yolov3_configs = {\"yolov3\": os.path.join(config_dir, 'yolov3.cfg'),\n",
    "                  \"yolov3-rico\": os.path.join(config_dir, 'yolov3-rico.cfg'),\n",
    "                  \"yolov3-rico2k\": os.path.join(config_dir, 'yolov3-rico2k.cfg'),\n",
    "                  \"yolov3-rico5box\": os.path.join(config_dir, 'yolov3-rico5box.cfg'),\n",
    "                  \"yolov3-rico10k\": os.path.join(config_dir, 'yolov3-rico10k.cfg'),\n",
    "                  \"yolov3-ricotext\": os.path.join(config_dir, 'yolov3-ricotext.cfg'),\n",
    "                  \"yolov3-custom\": os.path.join(config_dir, 'yolov3-custom.cfg')}\n",
    "data\n",
    "weights_dir = os.path.join(BASE_DIR, 'weights')\n",
    "rico_weights = {\"rico\": os.path.join(weights_dir, 'rico'), \n",
    "                 \"rico2k\": os.path.join(weights_dir, 'rico2k'), \n",
    "                 \"rico5box\": os.path.join(weights_dir, 'rico5box'), \n",
    "                 \"rico10k\": os.path.join(weights_dir, 'rico10k'), \n",
    "                 \"ricotext\": os.path.join(weights_dir, 'ricotext')}\n",
    "base_data_dir = os.path.join(BASE_DIR, 'tmp', 'data')\n",
    "base_train_dir = os.path.join(base_data_dir, 'train')\n",
    "base_test_dir = os.path.join(base_data_dir, 'test')\n",
    "extensions = {\"image\": '.jpg', \"label\": '.txt'}\n",
    "classes = {\n",
    "    \"lv_btn\": {\"name\": \"button\", \"index\": 0},\n",
    "    \"lv_checkbox\": {\"name\": \"checkbox\", \"index\": 1},\n",
    "    \"lv_label\": {\"name\": \"label\", \"index\": 2},\n",
    "    \"lv_slider\": {\"name\": \"slider\", \"index\": 3},\n",
    "    \"lv_switch\": {\"name\": \"switch\", \"index\": 4}\n",
    "}\n",
    "class_names = [classes[key][\"name\"] for key in classes.keys()]\n",
    "widget_names = [key for key in classes.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Check if CUDA (GPU support) is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class YoloDataset(Dataset):\n",
    "    def __init__(self, image_folder, label_folder, S=[13, 26, 52], B=3, C=80, transform=None):\n",
    "        self.image_files = [os.path.join(image_folder, x) for x in os.listdir(image_folder)]\n",
    "        self.label_files = [os.path.join(label_folder, x) for x in os.listdir(label_folder)]\n",
    "        self.image_size = 416  # YOLOv3 uses 416x416 images\n",
    "        self.S = S  # List of scales\n",
    "        self.B = B  # Number of bounding boxes\n",
    "        self.C = C  # Number of classes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load and transform the image\n",
    "        image_file = self.image_files[index]\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Initialize label tensors for each scale\n",
    "        label_tensor_list = [torch.zeros((self.C + 5) * self.B, s, s) for s in self.S]\n",
    "\n",
    "        # Get correct label file for the image \n",
    "        # (rpartition will split from end of string to character: 0=path, 1=basename)\n",
    "        label_index = self.label_files.index(image_file.rpartition('/')[1]) # Use image basename to find label\n",
    "        # Load label\n",
    "        label_file = self.label_files[label_index]\n",
    "        boxes = []\n",
    "        with open(label_file) as f:\n",
    "            for line in f.readlines(): # Each line is a box\n",
    "                class_id, x_center, y_center, width, height = [\n",
    "                    float(x) for x in line.replace('\\n', '').split()\n",
    "                ]\n",
    "                boxes.append([class_id, x_center, y_center, width, height, 1])\n",
    "\n",
    "        # Fill the label tensors\n",
    "        for box in boxes:\n",
    "            class_id, x_center, y_center, width, height, confidence = box\n",
    "            # We assume that the annotations were normalized by the width and height of the image.\n",
    "            # i.e., x_center and width are divided by the width of the image\n",
    "            # and similarly for y_center and height.\n",
    "\n",
    "            # Assign the box to the tensor corresponding to the scale\n",
    "            for scale_idx, s in enumerate(self.S):\n",
    "                i, j = int(s * y_center), int(s * x_center)  # Which grid cell\n",
    "                anchor_on_scale = scale_idx  # Which anchor (here we're just using the index)\n",
    "                \n",
    "                # Locate the cell responsible and assign the bounding box\n",
    "                label_tensor = label_tensor_list[scale_idx]\n",
    "                label_tensor[..., i, j] = torch.tensor(\n",
    "                    [x_center, y_center, width, height, confidence] + [0] * self.C\n",
    "                )\n",
    "                label_tensor[class_id, i, j] = 1\n",
    "\n",
    "        return image, label_tensor_list\n",
    "\n",
    "# Usage\n",
    "image_dir = os.path.join(base_train_dir, 'images')\n",
    "label_dir = os.path.join(base_train_dir, 'labels')\n",
    "dataset = YoloDataset(image_dir, label_dir)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `S` is a list of the sizes of the feature maps at different scales.\n",
    "- `B` is the number of anchors used.\n",
    "- `C` is the number of classes in the dataset.\n",
    "- The label tensors are initialized as zero tensors for each feature map scale.\n",
    "- For each object in the image, the correct cell in each scale's feature map is located, and the bounding box and class label are placed in the corresponding position in the label tensor.\n",
    "- The bounding boxes are assumed to be normalized, with coordinates as fractions of the image dimensions. You may need to adjust this if your labels are in a different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from baseline\n",
    "import sys\n",
    "sys.path.append(os.path.join(BASE_DIR, 'baseline', 'PyTorch-YOLOv3'))\n",
    "from models import Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Initialize the YOLOv3 model\n",
    "num_classes = 4  # Replace with the number of classes in your dataset\n",
    "model = Darknet(num_classes).to(device)  # Make sure to pass the correct number of classes to the model\n",
    "\n",
    "# Load pre-trained weights (if available)\n",
    "model.load_state_dict(torch.load(rico_datasets[\"rico\"], map_location=device))\n",
    "\n",
    "# Continue with setting up your dataset and data loaders\n",
    "image_folder = os.path.join(base_train_dir, 'images')\n",
    "label_folder = os.path.join(base_train_dir, 'labels')\n",
    "\n",
    "# Define your transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize to input size\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "\n",
    "# Instantiate your custom dataset\n",
    "dataset = YoloDataset(image_folder, label_folder, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "model.train()  # Set the model to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "from loss import YoloLoss  # This should be the path to your YOLOv3 loss function implementation\n",
    "\n",
    "criterion = YoloLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 50 # Set the number of epochs to train for\n",
    "for epoch in range(num_epochs):\n",
    "    for imgs, targets in loader:\n",
    "        imgs, targets = imgs.to(device), [target.to(device) for target in targets]  # Move to the appropriate device\n",
    "        optimizer.zero_grad()\n",
    "        output = model(imgs)  # Forward pass\n",
    "        loss = compute_loss(output, targets)  # You'll need to define compute_loss according to YOLOv3 loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# compute_loss is a function you will need to define. It should calculate the loss for YOLOv3.\n",
    "# This will involve calculating the objectness loss, the class prediction loss,\n",
    "# and the bounding box regression loss. You will likely need to iterate through\n",
    "# each of the three scales that YOLOv3 outputs and calculate the loss for each,\n",
    "# then sum them up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
